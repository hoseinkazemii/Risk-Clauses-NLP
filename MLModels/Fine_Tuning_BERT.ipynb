{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qwX4IDypR5eB",
    "outputId": "7db73472-03d1-4574-f2c6-9418213e8fc8"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CwPW8Tlznt7j",
    "outputId": "03b07b11-1507-4ecf-be49-7363d5d504dc"
   },
   "outputs": [],
   "source": [
    "!pip install hazm\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading the libraries:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4giUiRXcRfo3"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import  codecs\n",
    "from tqdm import tqdm\n",
    "import hazm\n",
    "import os\n",
    "from transformers import BertConfig, BertTokenizer\n",
    "from transformers import TFBertModel, TFBertForSequenceClassification\n",
    "from transformers import glue_convert_examples_to_features\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QW-Wxja0Rfo4"
   },
   "source": [
    "**Configuration used in the script:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aM8yxsU2Rfo5"
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"data_dir\" : \"./Data/\",\n",
    "    \"model_dir\" : \"./BERT/\",\n",
    "    \"train_data_name\" : \"Dataset.csv\",\n",
    "    \"max_len\" : 50,\n",
    "    \"length_threshold\" : 128,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EML74mdvRfo6"
   },
   "source": [
    "**Reading Data:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vhs6zrI7Rfo6"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Thesis-BERT-Final/Data/Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZmFpjSkXRfo6"
   },
   "outputs": [],
   "source": [
    "clauses = df['clause']\n",
    "labels = df['risk']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Shuffle and split:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yRLIYjYgRnZP"
   },
   "outputs": [],
   "source": [
    "df = shuffle(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RCtx9Uq_Rfo6"
   },
   "outputs": [],
   "source": [
    "train = df.iloc[:int(0.8 * len(df)),:]\n",
    "dev = train.iloc[int(0.8 * len(train)):,:]\n",
    "train = train.iloc[:int(0.8 * len(train)),:]\n",
    "test = df.iloc[int(0.8 * len(df)):,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oaaI0H90cQyg",
    "outputId": "cb533715-dda6-4cbd-d2a4-ef08a2f4406c"
   },
   "outputs": [],
   "source": [
    "print(train.shape)\n",
    "print(dev.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "khb3aEWARfo7",
    "outputId": "d237efc6-4331-47c5-f5f1-6ed4ef2ac6ef"
   },
   "outputs": [],
   "source": [
    "train = train[['clause', 'risk']]\n",
    "test = test[['clause', 'risk']]\n",
    "dev = dev[['clause', 'risk']]\n",
    "\n",
    "# calculate the length of comments based on their words\n",
    "train['caluse_len_by_words'] = train['clause'].apply(lambda t: len(hazm.word_tokenize(t)))\n",
    "min_max_len = train[\"caluse_len_by_words\"].min(), train[\"caluse_len_by_words\"].max()\n",
    "print(f'Min: {min_max_len[0]} \\tMax: {min_max_len[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8w0ml-CpRfo7"
   },
   "outputs": [],
   "source": [
    "train = train[['clause', 'risk']]\n",
    "test = test[['clause', 'risk']]\n",
    "dev = dev[['clause', 'risk']]\n",
    "\n",
    "x_train, y_train = train['clause'].values.tolist(), train['risk'].values.tolist()\n",
    "x_test, y_test = test['clause'].values.tolist(), test['risk'].values.tolist()\n",
    "x_dev, y_dev = dev['clause'].values.tolist(), dev['risk'].values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BERT hyperparameters:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h1TsNKP8Rfo8"
   },
   "outputs": [],
   "source": [
    "# general config\n",
    "MAX_LEN = 128\n",
    "TRAIN_BATCH_SIZE = 16\n",
    "VALID_BATCH_SIZE = 16\n",
    "TEST_BATCH_SIZE = 16\n",
    "\n",
    "EPOCHS = 3\n",
    "EEVERY_EPOCH = 1000\n",
    "LEARNING_RATE = 2e-5\n",
    "CLIP = 0.0\n",
    "\n",
    "MODEL_NAME_OR_PATH = 'HooshvareLab/bert-fa-base-uncased'\n",
    "OUTPUT_PATH = '/pytorch_model.bin'\n",
    "\n",
    "os.makedirs(os.path.dirname(OUTPUT_PATH), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BMl08Xe6Rfo9",
    "outputId": "e4deb689-ef1c-4193-f85e-1eaea480f83b"
   },
   "outputs": [],
   "source": [
    "labels = list(sorted(train['risk'].unique()))\n",
    "label2id = {label: i for i, label in enumerate([int(l) for l in labels])}\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "print(f'label2id: {label2id}')\n",
    "print(f'id2label: {id2label}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading BERT Tokenizer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qNH5VrEXRfo9",
    "outputId": "d65b011f-7dbc-4187-b439-f07cb56163c2"
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME_OR_PATH)\n",
    "config = BertConfig.from_pretrained(\n",
    "    MODEL_NAME_OR_PATH, **{\n",
    "        'label2id': label2id,\n",
    "        'id2label': id2label,\n",
    "    })\n",
    "\n",
    "print(config.to_json_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model's prerequisites, trainig, and testing the model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bxvZpD1bRfo9"
   },
   "outputs": [],
   "source": [
    "class InputExample:\n",
    "    \"\"\" A single example for simple sequence classification. \"\"\"\n",
    "\n",
    "    def __init__(self, guid, text_a, text_b=None, label=None):\n",
    "        \"\"\" Constructs a InputExample. \"\"\"\n",
    "        self.guid = guid\n",
    "        self.text_a = text_a\n",
    "        self.text_b = text_b\n",
    "        self.label = label\n",
    "\n",
    "\n",
    "def make_examples(tokenizer, x, y=None, maxlen=128, output_mode=\"classification\", is_tf_dataset=True):\n",
    "    examples = []\n",
    "    y = y if isinstance(y, list) or isinstance(y, np.ndarray) else [None] * len(x)\n",
    "\n",
    "    for i, (_x, _y) in tqdm(enumerate(zip(x, y)), position=0, total=len(x)):\n",
    "        guid = \"%s\" % i\n",
    "        label = int(_y)\n",
    "        \n",
    "        if isinstance(_x, str):\n",
    "            text_a = _x\n",
    "            text_b = None\n",
    "        else:\n",
    "            assert len(_x) == 2\n",
    "            text_a = _x[0]\n",
    "            text_b = _x[1]\n",
    "        \n",
    "        examples.append(InputExample(guid=guid, text_a=text_a, text_b=text_b, label=label))\n",
    "    \n",
    "    features = glue_convert_examples_to_features(\n",
    "        examples, \n",
    "        tokenizer, \n",
    "        maxlen, \n",
    "        output_mode=output_mode, \n",
    "        label_list=list(np.unique(y)))\n",
    "\n",
    "    all_input_ids = []\n",
    "    all_attention_masks = []\n",
    "    all_token_type_ids = []\n",
    "    all_labels = []\n",
    "\n",
    "    for f in tqdm(features, position=0, total=len(examples)):\n",
    "        if is_tf_dataset:\n",
    "            all_input_ids.append(tf.constant(f.input_ids))\n",
    "            all_attention_masks.append(tf.constant(f.attention_mask))\n",
    "            all_token_type_ids.append(tf.constant(f.token_type_ids))\n",
    "            all_labels.append(tf.constant(f.label))\n",
    "        else:\n",
    "            all_input_ids.append(f.input_ids)\n",
    "            all_attention_masks.append(f.attention_mask)\n",
    "            all_token_type_ids.append(f.token_type_ids)\n",
    "            all_labels.append(f.label)\n",
    "\n",
    "    if is_tf_dataset:\n",
    "        dataset = tf.data.Dataset.from_tensor_slices(({\n",
    "            'input_ids': all_input_ids,\n",
    "            'attention_mask': all_attention_masks,\n",
    "            'token_type_ids': all_token_type_ids\n",
    "        }, all_labels))\n",
    "\n",
    "        return dataset, features\n",
    "    \n",
    "    xdata = [np.array(all_input_ids), np.array(all_attention_masks), np.array(all_token_type_ids)]\n",
    "    ydata = all_labels\n",
    "\n",
    "    return [xdata, ydata], features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DrDIqSdqRfo-",
    "outputId": "b27f1e91-684d-4360-aef4-d65bfec2b830"
   },
   "outputs": [],
   "source": [
    "train_dataset_base, train_examples = make_examples(tokenizer, x_train, y_train, maxlen=128)\n",
    "valid_dataset_base, valid_examples = make_examples(tokenizer, x_dev, y_dev, maxlen=128)\n",
    "\n",
    "test_dataset_base, test_examples = make_examples(tokenizer, x_test, y_test, maxlen=128)\n",
    "[xtest, ytest], test_examples = make_examples(tokenizer, x_test, y_test, maxlen=128, is_tf_dataset=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xo9Bbu-zRfo-"
   },
   "outputs": [],
   "source": [
    "def get_training_dataset(dataset, batch_size):\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.shuffle(2048)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def get_validation_dataset(dataset, batch_size):\n",
    "    dataset = dataset.batch(batch_size)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rvpmda8tRfo_"
   },
   "outputs": [],
   "source": [
    "train_dataset = get_training_dataset(train_dataset_base, TRAIN_BATCH_SIZE)\n",
    "valid_dataset = get_training_dataset(valid_dataset_base, VALID_BATCH_SIZE)\n",
    "\n",
    "train_steps = len(train_examples) // TRAIN_BATCH_SIZE\n",
    "valid_steps = len(valid_examples) // VALID_BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TT_OruNsRfo_"
   },
   "outputs": [],
   "source": [
    "def build_model(model_name, config, learning_rate=3e-5):\n",
    "    model = TFBertForSequenceClassification.from_pretrained(model_name, config=config)\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=[metric])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RdJggr8hRfo_",
    "outputId": "62703387-f6e6-4991-b15f-2502d212023f"
   },
   "outputs": [],
   "source": [
    "model = build_model(MODEL_NAME_OR_PATH, config, learning_rate=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qW4Fy3GnRfpA",
    "outputId": "59af37e3-6b9f-49d0-8f16-c93de01f4375"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "r = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=valid_dataset,\n",
    "    steps_per_epoch=train_steps,\n",
    "    validation_steps=valid_steps,\n",
    "    epochs=EPOCHS,\n",
    "    verbose=1)\n",
    "\n",
    "final_accuracy = r.history['val_accuracy']\n",
    "print('FINAL ACCURACY MEAN: ', np.mean(final_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_xvU8cHuBufo",
    "outputId": "66a5a6f6-f722-49b6-c634-9d009d9bf990"
   },
   "outputs": [],
   "source": [
    "ev = model.evaluate(test_dataset_base.batch(TEST_BATCH_SIZE))\n",
    "print()\n",
    "print(f'Evaluation: {ev}')\n",
    "print()\n",
    "\n",
    "predictions = model.predict(xtest)\n",
    "ypred = predictions[0].argmax(axis=-1).tolist()\n",
    "\n",
    "print()\n",
    "print(classification_report(ytest, ypred, target_names=list(map(str,labels)), digits=4))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5RVyXTErjWXF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LHnzMiwAjWZZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eNtcpjDTjWbt"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Fine-Tuning-BERT.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
